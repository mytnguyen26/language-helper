{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# references https://www.analyticsvidhya.com/blog/2020/08/build-a-natural-language-generation-nlg-system-using-pytorch/\n",
    "# https://towardsdatascience.com/next-word-prediction-with-nlp-and-deep-learning-48b9fe0a17bf\n",
    "# https://www.kaggle.com/code/ashishpatel26/beginner-to-intermediate-nlp-tutorial\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ingest Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define file path to load\n",
    "path = \"../dataset/\"\n",
    "domain = \"chat\"\n",
    "file = \"dialogs.txt\"\n",
    "file_path = os.path.join(path,domain,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read text data\n",
    "with open(file_path, mode=\"r\") as file:\n",
    "    rows = file.readlines()\n",
    "    rows = [row.replace(\"\\t\",\" \").replace(\"\\n\", \"\") for row in rows]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"hi, how are you doing? i'm fine. how about yourself?\",\n",
       " \"i'm fine. how about yourself? i'm pretty good. thanks for asking.\",\n",
       " \"i'm pretty good. thanks for asking. no problem. so how have you been?\",\n",
       " \"no problem. so how have you been? i've been great. what about you?\",\n",
       " \"i've been great. what about you? i've been good. i'm in school right now.\",\n",
       " \"i've been good. i'm in school right now. what school do you go to?\",\n",
       " 'what school do you go to? i go to pcc.',\n",
       " 'i go to pcc. do you like it there?',\n",
       " \"do you like it there? it's okay. it's a really big campus.\",\n",
       " \"it's okay. it's a really big campus. good luck with school.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Morphological Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lexical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mynguyen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [nltk.sent_tokenize(row)[0] for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi, how are you doing?',\n",
       " \"i'm fine.\",\n",
       " \"i'm pretty good.\",\n",
       " 'no problem.',\n",
       " \"i've been great.\",\n",
       " \"i've been good.\",\n",
       " 'what school do you go to?',\n",
       " 'i go to pcc.',\n",
       " 'do you like it there?',\n",
       " \"it's okay.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each sentences\n",
    "word_token = nltk.word_tokenize(sentences[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', ',', 'how', 'are', 'you', 'doing', '?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame(sentences, columns=[\"text\"]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index  text                                          \n",
       "0      hi, how are you doing?                            1\n",
       "2488   how much were they?                               1\n",
       "2476   yeah.                                             1\n",
       "2477   i want to be a baseball player when i grow up.    1\n",
       "2478   me too.                                           1\n",
       "                                                        ..\n",
       "1246   some men do, but not me.                          1\n",
       "1247   i'm watching you.                                 1\n",
       "1248   i'm an open book.                                 1\n",
       "1249   if i catch you, you'll be sorry.                  1\n",
       "3724   but i do all my writing with my right hand.       1\n",
       "Length: 3725, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: hi, how are you doing? i'm fine. how about yourself?\n",
      "token: ['hi', ',', 'how', 'are', 'you', 'doing', '?', 'i', \"'m\", 'fine', '.', 'how', 'about', 'yourself', '?']\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(rows[0])\n",
    "print(f\"Input: {rows[0]}\")\n",
    "print(f\"token: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Syntactic Analysis\n",
    "- deal with grammatical **structure** and **relation** of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Semantic Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Markov Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from typing import List\n",
    "\n",
    "hash_map = {}\n",
    "# for each sentence in sentences\n",
    "# generate ngrams\n",
    "\n",
    "def matching_set(ngrams_model, tokens):\n",
    "  \"\"\"\n",
    "  TODO\n",
    "  \"\"\"\n",
    "  match_grams = []\n",
    "  count = 0\n",
    "  for grams in ngrams_model:\n",
    "    print(f\"compare {tokens} with {grams[:len(tokens)]}\")\n",
    "\n",
    "    if grams[:len(tokens)] == tokens:\n",
    "      match_grams.append(grams)\n",
    "      count += 1\n",
    "  return match_grams\n",
    "\n",
    "def markov_next_word(match_grams):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    chosen_word = \"\"\n",
    "    p_chosen_word = -1\n",
    "    # P(next_word | prev_word)\n",
    "    for candidate in match_grams:\n",
    "        next_word = candidate[-1]\n",
    "        if next_word not in hash_map.keys():\n",
    "            hash_map[next_word] = (1, 1/len(match_grams))\n",
    "        else:\n",
    "            hash_map[next_word][0] += 1\n",
    "            hash_map[next_word][1] = hash_map[next_word][0]/len(match_grams)\n",
    "        if hash_map[next_word][1] > p_chosen_word:\n",
    "            chosen_word = next_word\n",
    "            p_chosen_word = hash_map[next_word][1]\n",
    "        elif hash_map[next_word][1] > p_chosen_word:\n",
    "            np.random.choice([chosen_word, next_word])\n",
    "        print(next_word)\n",
    "    return (chosen_word, p_chosen_word)\n",
    "\n",
    "def make_model(batch_sentences: List[str], n: int):\n",
    "  # making models\n",
    "  model = []\n",
    "  for sentence in batch_sentences:\n",
    "    n_grams = ngrams(nltk.word_tokenize(sentence), n)\n",
    "    for grams in n_grams:\n",
    "      model.append(grams)\n",
    "      print(f\"last word should be the next word used for prediction, or target: {grams[n-1]}\")\n",
    "      print(f\"prev words {grams[:n-1]}\")\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last word should be the next word used for prediction, or target: are\n",
      "prev words ('hi', 'how')\n",
      "last word should be the next word used for prediction, or target: you\n",
      "prev words ('how', 'are')\n",
      "last word should be the next word used for prediction, or target: doing\n",
      "prev words ('are', 'you')\n",
      "last word should be the next word used for prediction, or target: the\n",
      "prev words ('hi', 'how')\n",
      "last word should be the next word used for prediction, or target: kids\n",
      "prev words ('how', 'the')\n"
     ]
    }
   ],
   "source": [
    "n_grams = 3\n",
    "\n",
    "# before getting to this stage, must clean up the data set to remove\n",
    "# punctuation marks\n",
    "# standardize word, for example I'm --> I am\n",
    "\n",
    "test_sentences = [\"hi how are you doing\",\n",
    "            \"hi how the kids\"]\n",
    "model = make_model(test_sentences, n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hi', 'how', 'are'),\n",
       " ('how', 'are', 'you'),\n",
       " ('are', 'you', 'doing'),\n",
       " ('hi', 'how', 'the'),\n",
       " ('how', 'the', 'kids')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare ('hi', 'how') with ('hi', 'how')\n",
      "compare ('hi', 'how') with ('how', 'are')\n",
      "compare ('hi', 'how') with ('are', 'you')\n",
      "compare ('hi', 'how') with ('hi', 'how')\n",
      "compare ('hi', 'how') with ('how', 'the')\n"
     ]
    }
   ],
   "source": [
    "input_string = \"hello hi how\"\n",
    "match_grams = matching_set(model, tuple(nltk.word_tokenize(input_string))[-(n_grams-1):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hi', 'how', 'are'), ('hi', 'how', 'the')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are\n",
      "the\n",
      "Hash Map {'are': (1, 0.5), 'the': (1, 0.5)}\n",
      "Predict next word 'are' with  0.5\n"
     ]
    }
   ],
   "source": [
    "chosen_word, p_chosen_word = markov_next_word(match_grams=match_grams)\n",
    "hash_map\n",
    "print(\"Hash Map\", hash_map)\n",
    "print(f\"Predict next word '{chosen_word}' with  {p_chosen_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Markov Language Model Evaluation (Perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. LSTM\n",
    "\n",
    "Note:\n",
    "+ Pytorchâ€™s LSTM expects all of its inputs to be 3D tensors\n",
    "+ semantics of the axes of these tensors is important  \n",
    "-> first axis is the sequence itself,  \n",
    "-> the second indexes instances in the mini-batch,   \n",
    "-> the third indexes elements of the input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Define NN model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import FloatTensor, randn, zeros\n",
    "\n",
    "# optimization function\n",
    "import torch.optim as optim\n",
    "\n",
    "\"\"\"\n",
    "From Deep Learning for NLP and Speech basic pytorch example\n",
    "http://seba1511.net/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\"\"\"\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        # self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype = FloatTensor\n",
    "N, input_size, hidden_size, output_size = 64, 10, 10, 10\n",
    "data = randn(input_size, hidden_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=input_size)\n",
    "# optimizer = optim.Adam(rnn.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input = Variable(data)\n",
    "hidden = Variable(zeros(1, rnn.hidden_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e65760c262d5713fae1aa5f5c026ded1a51727bf6811c13a452d385d1e43469"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
